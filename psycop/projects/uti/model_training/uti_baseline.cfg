# XGboost odel configuration / settings
[project_info]
experiment_path = "E:/shared_resources/uti/model_training/"

[logger]
@loggers = "multi_logger"

[logger.*.terminal]
@loggers = "terminal_logger"

[logger.*.mlflow]
@loggers = "mlflow_logger"
experiment_name = "UTI"
run_name = "None"
postpone_run_creation_to_first_log = True

[logger.*.disk_logger]
@loggers = "disk_logger"
run_path = ${project_info.experiment_path}${logger.*.mlflow.experiment_name}

# Using cross-validation trainer
[trainer]
@trainers = "crossval_trainer"
uuid_col_name = "prediction_time_uuid"
outcome_col_name = "outc_uti_value_within_0_to_3_days_max_fallback_0"
n_splits = 5
group_col_name = "dw_ek_borger"

[trainer.metric]
@metrics = "binary_auroc"

# Feature set path
[trainer.training_data]
@data = "parquet_vertical_concatenator"
paths = ["E:/shared_resources/uti/flattened_datasets/uti_feature_set_antibiotics_outcome_definition/uti_feature_set_antibiotics_outcome_definition.parquet"]
validate_on_init = False

#################
# Preprocessing #
#################
[trainer.preprocessing_pipeline]
@preprocessing = "baseline_preprocessing_pipeline"

[trainer.preprocessing_pipeline.*.split_filter]
@preprocessing = "outcomestratified_split_filter"
splits_to_keep = ["train", "val"]
id_col_name = "dw_ek_borger"

[trainer.preprocessing_pipeline.*.bool_to_int]
@preprocessing = "bool_to_int"

# Filter rows
[trainer.preprocessing_pipeline.*.age_filter]
@preprocessing = "age_filter"
min_age = 6570
max_age = 365000
age_col_name = "pred_age_days_fallback_0"

[trainer.preprocessing_pipeline.*.sufficient_lookahead_filter]
@preprocessing = "window_filter"
timestamp_col_name = "timestamp"
n_days = 2
direction = "ahead"

[trainer.preprocessing_pipeline.*.sufficient_lookbehind_filter]
@preprocessing = "window_filter"
timestamp_col_name = "timestamp"
n_days = 365
direction = "behind"

# Only keep prediction times for the first 30 days of each admission
[trainer.preprocessing_pipeline.*.long_admissions_filter]
@preprocessing = "value_filter"
column_name = "pred_adm_day_count"
threshold_value = 30
direction = "before"

[trainer.preprocessing_pipeline.*.regex_remove_adm_uuid_col]
@preprocessing = "regex_column_blacklist"
* = ["adm_uuid"]

# Filter columns
## Outcomes
[trainer.preprocessing_pipeline.*.outcome_selector]
@preprocessing = "filter_columns_within_subset"
subset_rule = "outc_.+"
keep_matching = ".+3.+"

## Remove timestamp columns
[trainer.preprocessing_pipeline.*.temporal_col_filter]
@preprocessing = "temporal_col_filter"

# Validate column assumptions
[trainer.preprocessing_pipeline.*.columns_exist]
@preprocessing = "column_exists_validator"
column_names = ["prediction_time_uuid", "pred_age_days_fallback_0", "pred_sex_female_fallback_0"]
[trainer.preprocessing_pipeline.*.column_prefix_count_expectation]
@preprocessing = "column_prefix_count_expectation"
column_expectations = [["outc_", 1], ["prediction_timestamp", 0]]

#############
# Estimator #
#############
# Use XGboost
[trainer.task.task_pipe.sklearn_pipe.*.model]
@estimator_steps = "xgboost"

########
# Task #
########
[trainer.task]
@tasks = "binary_classification"

[trainer.task.task_pipe]
@task_pipelines = "binary_classification_pipeline"

[trainer.task.task_pipe.sklearn_pipe]
@task_pipelines = "pipe_constructor"


