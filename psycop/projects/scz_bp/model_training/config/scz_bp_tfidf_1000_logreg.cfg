[logger]
@loggers = "multi_logger"

[logger.*.terminal_logger]
@loggers = "terminal_logger"

[logger.*.mlflow_logger]
@loggers = "mlflow_logger"
experiment_name = "sczbp/tfidf_1000_logreg"
postpone_run_creation_to_first_log = True


[trainer]
@trainers = "crossval_trainer"
outcome_col_name = "outc_first_scz_or_bp_within_1825_days_maximum_fallback_0_dichotomous"
n_splits = 5
group_col_name = "dw_ek_borger"
uuid_col_name = "prediction_time_uuid"

[trainer.metric]
@metrics = "binary_auroc"

[trainer.training_data]
@data = "parquet_vertical_concatenator"
paths = ["E:/shared_resources/scz_bp/flattened_datasets/l1_l4-lookbehind_183_365_730-all_relevant_tfidf_1000_lookbehind_730.parquet"]


#################
# Preprocessing #
#################
[trainer.preprocessing_pipeline]
@preprocessing = "baseline_preprocessing_pipeline"

# Rows
[trainer.preprocessing_pipeline.*.split_filter]
@preprocessing = "regional_data_filter"
splits_to_keep = ["train", "val"]
regional_move_df = null
timestamp_col_name = "timestamp"
id_col_name = "dw_ek_borger"
region_col_name = "region"
timestamp_cutoff_col_name = "first_regional_move_timestamp"

[trainer.preprocessing_pipeline.*.lookahead_distance_filter]
@preprocessing = "window_filter"
n_days = 1825
direction = "ahead"
timestamp_col_name = "timestamp"

[trainer.preprocessing_pipeline.*.age_filter]
@preprocessing = "age_filter"
min_age = 18
max_age = 99
age_col_name = "pred_age_in_years"

# Columns
[trainer.preprocessing_pipeline.*.regex_meta_blacklist]
@preprocessing = "regex_column_blacklist"
* = ["meta_.*"]

[trainer.preprocessing_pipeline.*.columns_exist]
@preprocessing = "column_exists_validator"
column_names = ["pred_age_in_years", "prediction_time_uuid"]

[trainer.preprocessing_pipeline.*.outcome_selector]
@preprocessing = "filter_columns_within_subset"
subset_rule = "outc_.+"
keep_matching = ".+1825.+"

[trainer.preprocessing_pipeline.*.temporal_col_filter]
@preprocessing = "temporal_col_filter"

[trainer.preprocessing_pipeline.*.layer_selector]
@preprocessing = "filter_columns_within_subset"
subset_rule = "pred_.+layer.+"
keep_matching = ".+_layer_(5).+"

# [trainer.preprocessing_pipeline.*.lookbehind_selector]
# @preprocessing = "filter_columns_within_subset"
# subset_rule = "pred_.+"
# keep_matching = ".+_(730)_.+"

# [trainer.preprocessing_pipeline.*.regex_remove_text_embedding]
# @preprocessing = "regex_column_blacklist"
# * = ["pred_.+tfidf.+"]


[trainer.preprocessing_pipeline.*.column_prefix_count_expectation]
@preprocessing = "column_prefix_count_expectation"
column_expectations = [["outc_", 1]]

[trainer.preprocessing_pipeline.*.bool_to_int]
@preprocessing = "bool_to_int"



########
# Task #
########
[trainer.task]
@tasks = "binary_classification"


[trainer.task.task_pipe]
@task_pipelines = "binary_classification_pipeline"

[trainer.task.task_pipe.sklearn_pipe]
@task_pipelines = "pipe_constructor"

[trainer.task.task_pipe.sklearn_pipe.*.imputer]
@estimator_steps_suggesters = "imputation_suggester"
strategies = ["mean", "median", "most_frequent"]


[trainer.task.task_pipe.sklearn_pipe.*.model]
@estimator_steps_suggesters = "logistic_regression_suggester"

