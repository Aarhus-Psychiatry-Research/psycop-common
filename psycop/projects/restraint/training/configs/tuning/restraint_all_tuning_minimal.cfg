#################
#   Logging     #
#################

[project_info]
experiment_path = "E:/shared_resources/restraint/training/restraint_all_tuning_minimal_adm_day_count"

[logger]
@loggers = "multi_logger"

[logger.*.terminal]
@loggers = "terminal_logger"

[logger.*.mlflow]
@loggers = "mlflow_logger"
experiment_name = "restraint_all_tuning_minimal_adm_day_count"
postpone_run_creation_to_first_log = True

[logger.*.disk_logger]
@loggers = "disk_logger"
run_path = ${project_info.experiment_path}${logger.*.mlflow.experiment_name}

#################
#     Setup     #
#################

[trainer]
@trainers = "crossval_trainer"
uuid_col_name = "prediction_time_uuid"
outcome_col_name = "outc_outcome_all_restraint_within_2_days_boolean_fallback_0_dichotomous"
n_splits = 5
group_col_name = "dw_ek_borger"

[trainer.metric]
@metrics = "binary_auroc"

[trainer.training_data]
@data = "parquet_vertical_concatenator"
paths = ["E:/shared_resources/restraint/flattened_datasets/full_feature_set_structured_tfidf_750_all_outcomes/full_with_pred_adm_day_count.parquet"]
#################
# Preprocessing #
#################

[trainer.preprocessing_pipeline]
@preprocessing = "baseline_preprocessing_pipeline"

[trainer.preprocessing_pipeline.*.split_filter]
@preprocessing = "outcomestratified_split_filter"
splits_to_keep = ["train", "val"]

[trainer.preprocessing_pipeline.*.bool_to_int]
@preprocessing = "bool_to_int"

# Filter rows 
[trainer.preprocessing_pipeline.*.sufficient_lookahead_filter]
@preprocessing = "window_filter"
timestamp_col_name = "timestamp"
n_days = 2
direction = "ahead"

# [trainer.preprocessing_pipeline.*.sufficient_lookbehind_filter]
# @preprocessing = "window_filter"
# timestamp_col_name = "timestamp"
# n_days = 730
# direction = "behind"

# [trainer.preprocessing_pipeline.*.sufficient_lookbehind_filter]
# @suggesters = "sufficient_window_filter_suggester"
# timestamp_col_name = "timestamp"
# n_days = [0, 30, 180, 730]
# direction = "behind"

# Filter columns

# [trainer.preprocessing_pipeline.*.lookbehind_combination_suggester]
# @suggesters = "lookbehind_combination_filter_suggester"
# lookbehinds = ["{730}", "{1, 3, 10}", "{1, 7, 30, 730}", "{1, 3, 7, 10, 30, 180, 365, 730}"]
# pred_col_prefix = "pred_"

## Outcome

[trainer.preprocessing_pipeline.*.outcome_selector]
@preprocessing = "filter_columns_within_subset"
subset_rule = "outc_.+"
keep_matching = ".+_all_.+"

[trainer.preprocessing_pipeline.*.predictor_selector]
@preprocessing = "filter_columns_within_subset"
subset_rule = "pred_.+"
keep_matching = "(.+age_in_years|.+sex_female|.+sindlaeggelse_within_1_days_b+.|.+stilbageholdelse_within_1_days_b+.|.+e_checklist_within_1_days_max+.|.+f0_disorders_within_730_days_b+.|.+f1_disorders_within_730_days_b+.|.+f2_disorders_within_730_days_b+.|.+f3_disorders_within_730_days_b+.|.+f4_disorders_within_730_days_b+.|.+f5_disorders_within_730_days_b+.|.+f6_disorders_within_730_days_b+.|.+f7_disorders_within_730_days_b+.|.+f8_disorders_within_730_days_b+.|.+f9_disorders_within_730_days_b+.|.+adm_day_c+.)"

## Remove timestamp columns
[trainer.preprocessing_pipeline.*.temporal_col_filter]
@preprocessing = "temporal_col_filter"

## Remove tfidf
# [trainer.preprocessing_pipeline.*.regex_remove_text_embedding]
# @preprocessing = "regex_column_blacklist"
# * = ["pred_.+tfidf.+"]

# [trainer.preprocessing_pipeline.*.regex_remove_text_embedding]
# @suggesters = "blacklist_filter_suggester"
# regex_pattern = ["pred_.+tfidf.+", "noop"]

# Validate

[trainer.preprocessing_pipeline.*.columns_exist]
@preprocessing = "column_exists_validator"
column_names = ["prediction_time_uuid", "pred_age_in_years", "pred_sex_female"]

[trainer.preprocessing_pipeline.*.column_prefix_count_expectation]
@preprocessing = "column_prefix_count_expectation"
column_expectations = [["outc_", 1], ["prediction_timestamp", 0]]



#################
#     Task      #
#################

[trainer.task]
@tasks = "binary_classification"

[trainer.task.task_pipe]
@task_pipelines = "binary_classification_pipeline"

[trainer.task.task_pipe.sklearn_pipe]
@task_pipelines = "pipe_constructor"


#################
#     Model     #
#################

[trainer.task.task_pipe.sklearn_pipe.*.imputer]
@estimator_steps_suggesters = "imputation_suggester"
strategies = ["most_frequent", "mean"]

[trainer.task.task_pipe.sklearn_pipe.*.scaler]
@estimator_steps_suggesters = "scaler_suggester"
strategies = ["standard", "noop"]

[trainer.task.task_pipe.sklearn_pipe.*.feature_selection]
@estimator_steps_suggesters = "feature_selection_suggester"
score_functions = ["f_classif", "noop"]
percentiles = [20, 40, 60, 80]

[trainer.task.task_pipe.sklearn_pipe.*.model]
@estimator_steps_suggesters = "xgboost_suggester"

[trainer.task.task_pipe.sklearn_pipe.*.model.learning_rate]
low = 1e-8
high = 0.1
logarithmic = True