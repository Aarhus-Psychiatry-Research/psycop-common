
data:
  n_training_samples: None  # Number of training samples to use, defaults to None in which cases it uses all samples.
  drop_if_outcome_before_date: 2013-01-01
  min_lookahead_days: 365 # (int): Drop all prediction times where (max timestamp in the dataset) - (current timestamp) is less than min_lookahead_days
  lookahead_days:
preprocessing:
  convert_to_boolean: False # (Boolean): defaults to False
  convert_datetimes_to: "ordinal" # (str): Options include "ordinal" 
model:
  model_name: "xgboost" # (str): Model include "xgboost"
  xgboost: # Hyperparameters for xgboost: See more here: https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier
    n_estimators: 100
training:
  n_splits: 5 # (int): number of k-fold during CV
evaluation:
  wandb: False
