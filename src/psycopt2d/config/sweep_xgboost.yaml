# @package _global_
defaults:
  - project: test_project
  - data: test_data
  - preprocessing: default_preprocessing
  - training: default_training
  - evaluation: default_evaluation
  - sweeper: optuna
  - _self_

model:
  model_name: xgboost # (str): Model, can currently take xgboost

hydra:
  sweeper:
    params:
      ++model.hyperparameters.n_estimators: choice(20, 30)
      ++model.hyperparameters.lambda: tag(log, interval(1e-8, 1.0))
      ++model.hyperparameters.alpha: tag(log, interval(1e-8, 1.0))
      ++model.hyperparameters.booster: choice("gbtree", "gblinear")
      ++model.hyperparameters.max_depth: int(interval(1, 9))
      ++model.hyperparameters.learning_rate: tag(log, interval(1e-8, 1.0))
      ++model.hyperparameters.gamma: tag(log, interval(1e-8, 1.0))
      ++model.hyperparameters.grow_policy: choice("depthwise", "lossguide")